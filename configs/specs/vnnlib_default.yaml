# VNNLIB Benchmark Specification Configuration
#
# Optimized preset for creating verification specs from VNN-COMP
# VNNLIB benchmark instances with ONNX models.
#
# Used by: VNNLibSpecCreator

# Epsilon values (not typically used for VNNLIB)
# VNNLIB specs already contain concrete constraints
# These are fallback values if needed for additional perturbations
epsilons:
  - 0.01

# Margin values (not typically used for VNNLIB)
# VNNLIB specs already define output constraints
margins:
  - 0.0

# Input specification types
# VNNLIB typically provides BOX constraints
# LIN_POLY may be needed for some benchmarks with linear constraints
input_kinds:
  - BOX
  - LIN_POLY

# Output specification types
# VNNLIB typically provides LINEAR_LE constraints (c^T * y <= d)
# RANGE may be needed for simple bounds
output_kinds:
  - LINEAR_LE
  - RANGE

# Combination strategy
# For VNNLIB, use 'minimal' since specs are already defined in .vnnlib files
# Each instance has exactly one input spec and one output spec
combination_strategy: minimal

# Balanced strategy parameters (not used with 'minimal' strategy)
balanced_params:
  max_input_specs: 1
  max_output_specs: 1
  max_total_combinations: 1

# Validation settings
validation:
  # Validate specs against converted PyTorch models
  validate_shapes: true
  
  # Skip invalid specs rather than failing
  skip_invalid: true

# VNNLIB-specific settings
vnnlib:
  # Maximum instances per category
  # null = process all instances in category
  # Set to a number (e.g., 10) to limit for quick testing
  max_instances: null
  
  # Whether to simplify ONNX models before PyTorch conversion
  # Simplification can improve conversion success rate
  simplify_onnx: true
  
  # ONNX conversion settings
  onnx_conversion:
    # Attempt conversion even if ONNX validation fails
    force_conversion: false
    
    # Validate converted PyTorch model with dummy input
    test_conversion: true

# ONNX model handling
onnx:
  # Input shape inference method
  # Options: 'from_onnx', 'from_vnnlib', 'auto'
  shape_inference: 'auto'
  
  # Handle dynamic batch dimensions
  # If true, assumes first dimension is batch and removes it
  handle_batch_dim: true

# VNNLIB parsing options
vnnlib_parsing:
  # How to extract input tensor from constraints
  # Options: 'center', 'lower_bound', 'upper_bound', 'midpoint'
  # 'center' = (lb + ub) / 2 (default)
  input_tensor_method: 'center'
  
  # Handle missing output constraints
  # If VNNLIB has no output constraints, use fallback spec
  fallback_output_spec: 'RANGE'

# Category-specific settings (optional overrides)
category_overrides:
  # Example: ACAS Xu benchmarks
  acasxu:
    max_instances: 50
    simplify_onnx: false
  
  # Example: MNIST fully connected
  mnist_fc:
    max_instances: 100
    test_conversion: true
  
  # Example: CIFAR10 ResNet
  cifar10_resnet:
    max_instances: 20
    simplify_onnx: true

# Logging configuration
logging:
  level: "INFO"
  show_progress: true
  
  # Show detailed ONNX conversion logs
  verbose_conversion: false
  
  # Show detailed VNNLIB parsing logs
  verbose_parsing: false

# Performance settings
performance:
  # Cache converted PyTorch models to avoid repeated conversion
  cache_models: true
  
  # Parallel processing for multiple instances
  parallel: false
  num_workers: 1

# Download settings
download:
  # Base URL for VNN-COMP benchmarks
  vnncomp_repo: "https://raw.githubusercontent.com/ChristopherBrix/vnncomp_benchmarks/main"
  
  # Automatic retry on download failure
  retry_failed: true
  max_retries: 3

# Notes for users
notes: |
  VNNLIB Benchmark Preset:
  - Designed for VNN-COMP benchmark instances
  - Minimal combination strategy (1 input spec, 1 output spec per instance)
  - Automatically downloads from VNN-COMP GitHub repository
  - Converts ONNX models to PyTorch for unified verification interface
  - Parses VNNLIB SMT-LIB format to extract constraints
  - Handles common VNN-COMP categories (MNIST, CIFAR10, ACAS Xu, etc.)
  
  Usage:
    1. Download category: download_vnnlib_category("mnist_fc")
    2. Create specs: creator = VNNLibSpecCreator(); results = creator.create_specs_for_data_model_pairs()
    3. Each result contains: (category, instance_id, pytorch_model, [input_tensor], [(input_spec, output_spec)])
